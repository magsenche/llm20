{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pathlib\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import transformers\n",
    "from submission.utils import default, prompt\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "\n",
    "def format_message(role: str, content: str) -> dict:\n",
    "    return {\"role\": role, \"content\": content}\n",
    "\n",
    "\n",
    "NF = len(default.first_questions)\n",
    "KAGGLE_AGENT = pathlib.Path(\"/kaggle_simulations/agent\")\n",
    "\n",
    "if KAGGLE_AGENT.exists():\n",
    "    model = \"llama-3.1/transformers/8b-instruct/1\"\n",
    "    model_path = KAGGLE_AGENT / \"input\" / model\n",
    "\n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_path,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    def call_model(\n",
    "        messages: list[dict],\n",
    "        max_new_tokens: int = 16,\n",
    "        temperature: int = 0.6,\n",
    "    ) -> dict[dict[str]]:\n",
    "        outputs = pipeline(\n",
    "            messages, max_new_tokens=max_new_tokens, temperature=temperature\n",
    "        )\n",
    "        return outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "else:\n",
    "    import ollama\n",
    "\n",
    "    model = \"llama3.1:8b\"\n",
    "\n",
    "    def call_model(\n",
    "        messages: list[dict],\n",
    "        max_new_tokens: int = 16,\n",
    "        temperature: int = 0.6,\n",
    "    ) -> dict[dict[str]]:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            options={\"num_predict\": max_new_tokens, \"temperature\": temperature},\n",
    "        )\n",
    "        return response[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    max_new_token: int = 32\n",
    "    temperature: int = 0.6\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sys_prompt: str = \"You are an AI agent\",\n",
    "    ) -> None:\n",
    "        self.sys_prompt = sys_prompt\n",
    "        self.state = []\n",
    "        self.default = [\"default res\"]\n",
    "\n",
    "    def __call__(self, obs, cfg) -> str:\n",
    "        try:\n",
    "            self.config_state(obs)\n",
    "            return self.result(obs, cfg)\n",
    "        except:\n",
    "            return self.default_res()\n",
    "\n",
    "    def config_state(self, obs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_state(self, role: str, content: str | None) -> None:\n",
    "        if content is not None and len(content) > 0:\n",
    "            message = format_message(role, content)\n",
    "            self.state.append(message)\n",
    "\n",
    "    def result(self, obs, cfg) -> str:\n",
    "        response = call_model(self.state, self.max_new_token, self.temperature)\n",
    "        res = self.check(response)\n",
    "        return res\n",
    "\n",
    "    def check(self, response: str) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_res(self) -> str:\n",
    "        return random.choice(self.default)\n",
    "\n",
    "\n",
    "class Questioner(Agent):\n",
    "    max_new_token: int = 128\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(sys_prompt=prompt.questioner)\n",
    "\n",
    "    def config_state(self, obs):\n",
    "        self.reset_state(obs)\n",
    "        self.update_state(\"user\", \"Let's play !\")\n",
    "        for q, a in itertools.zip_longest(obs.questions, obs.answers):\n",
    "            self.update_state(\"assistant\", q)\n",
    "            self.update_state(\"user\", a)\n",
    "\n",
    "    def reset_state(self, obs) -> None:\n",
    "        self.state = []\n",
    "        clues = [\n",
    "            default.first_questions[i][yn] for i, yn in enumerate(obs.answers[:NF])\n",
    "        ]\n",
    "        intial_clues = \"a 'thing', \" + \", \".join(clues)\n",
    "        self.update_state(\"system\", self.sys_prompt.format(initial_clues=intial_clues))\n",
    "\n",
    "\n",
    "class Asker(Questioner):\n",
    "    temperature: int = 0.6\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.default = default.questions\n",
    "\n",
    "    def config_state(self, obs):\n",
    "        super().config_state(obs)\n",
    "        i = len(obs.questions) + 1\n",
    "        if obs.answers[-5:].count(\"no\") == 5:\n",
    "            ask_prompt = prompt.ask_5no.format(i=i)\n",
    "        elif obs.answers[-3:].count(\"no\") == 3:\n",
    "            ask_prompt = prompt.ask_3no.format(i=i)\n",
    "        else:\n",
    "            ask_prompt = prompt.ask.format(i=i)\n",
    "        self.update_state(\"user\", ask_prompt)\n",
    "\n",
    "    def result(self, obs, cfg) -> str:\n",
    "        i = len(obs.questions)\n",
    "        if i < NF:\n",
    "            res = default.first_questions[i][\"question\"]\n",
    "        else:\n",
    "            res = super().result(obs, cfg)\n",
    "        return res\n",
    "\n",
    "    def check(self, response: str) -> str:\n",
    "        print(f\"\\033[91m{response}\\033[0m\")\n",
    "        matched = re.match(r\".*\\?$\", response)\n",
    "        return response if matched else self.default_res()\n",
    "\n",
    "\n",
    "class Guesser(Questioner):\n",
    "    temperature: int = 0.6\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.default = default.guesses\n",
    "\n",
    "    def config_state(self, obs):\n",
    "        super().config_state(obs)\n",
    "        i = len(obs.guesses) + 1\n",
    "        self.update_state(\"user\", prompt.guess.format(i=i, guesses=obs.guesses))\n",
    "\n",
    "    def reset_state(self, obs):\n",
    "        super().reset_state(obs)\n",
    "        self.temperature = Guesser.temperature\n",
    "\n",
    "    def result(self, obs, cfg) -> str:\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < 0.8 * cfg.actTimeout:\n",
    "            results = super().result(obs, cfg).split(\"|\")\n",
    "            for res in results:\n",
    "                res = re.sub(r\"^(a|an|the)\\s+\", \"\", res.lower().strip())\n",
    "                if res not in obs.guesses and res.count(\" \") < 3:\n",
    "                    print(f\"\\033[95m{res}\\033[0m\")\n",
    "                    return res\n",
    "            self.temperature = min(0.2, self.temperature + 0.05)\n",
    "        return self.default_res()\n",
    "\n",
    "    def check(self, response: str) -> str:\n",
    "        print(f\"\\033[92m{response}\\033[0m\")\n",
    "        guesses = re.findall(\n",
    "            r\"\\*{2}([^\\*\\s].*?[^\\*\\s])\\*{2}\", response.replace(\"\\n\", \"\")\n",
    "        )\n",
    "        res = \"|\".join(guesses)\n",
    "        return res if res else self.default_res()\n",
    "\n",
    "\n",
    "class Answerer(Agent):\n",
    "    max_new_token: int = 16\n",
    "    temperature: int = 0.2\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(sys_prompt=prompt.answerer)\n",
    "        self.default = [\"yes\", \"no\"]\n",
    "\n",
    "    def config_state(self, obs):\n",
    "        self.reset_state(obs)\n",
    "        self.update_state(\n",
    "            \"user\",\n",
    "            prompt.answer.format(\n",
    "                keyword=obs.keyword, category=obs.category, question=obs.questions[-1]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def reset_state(self, obs) -> None:\n",
    "        self.state = []\n",
    "        self.update_state(\"system\", self.sys_prompt)\n",
    "\n",
    "    def check(self, response: str) -> str:\n",
    "        print(f\"\\033[93m{response}\\033[0m\")\n",
    "        return \"yes\" if \"yes\" in response.lower() else self.default_res()\n",
    "\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    match obs.turnType:\n",
    "        case \"ask\":\n",
    "            return Asker()(obs, cfg)\n",
    "        case \"answer\":\n",
    "            return Answerer()(obs, cfg)\n",
    "        case \"guess\":\n",
    "            return Guesser()(obs, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_environments\n",
    "import random\n",
    "\n",
    "\n",
    "def setup_env(keyword: str, alts: list[str] = []):\n",
    "    llm20env = kaggle_environments.envs.llm_20_questions.llm_20_questions\n",
    "    llm20env.category = \"things\"\n",
    "    if keyword:\n",
    "        llm20env.keyword_obj = {\"keyword\": keyword, \"alts\": alts}\n",
    "    else:\n",
    "        llm20env.keyword_obj = random.choice(llm20env.keywords_list[0][\"words\"])\n",
    "    llm20env.keyword = llm20env.keyword_obj[\"keyword\"]\n",
    "    llm20env.alts = llm20env.keyword_obj[\"alts\"]\n",
    "    print(f\"\\033[94m{llm20env.keyword}\\033[0m\")\n",
    "\n",
    "\n",
    "def run(keyword: str, alts: list[str] = []):\n",
    "    setup_env(keyword, alts)\n",
    "    env = kaggle_environments.make(environment=\"llm_20_questions\", debug=True)\n",
    "    env.run(\n",
    "        agents=[\n",
    "            agent_fn,\n",
    "            agent_fn,\n",
    "            \"random_guesser\",\n",
    "            \"random_answerer\",\n",
    "        ]\n",
    "    )\n",
    "    env.render(mode=\"ipython\", width=1080, height=700)\n",
    "\n",
    "\n",
    "for keyword in 5 * [\"\"]:\n",
    "    run(keyword)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
